{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8d_U6iIAEbQ"
   },
   "source": [
    "### Build and train the ResNeXT 50 and 101 network and retrain it by breast cancer data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "executionInfo": {
     "elapsed": 70026,
     "status": "ok",
     "timestamp": 1591273370395,
     "user": {
      "displayName": "FAEZEHSADAT SHAHIDI MAN181002",
      "photoUrl": "",
      "userId": "15928786153813768879"
     },
     "user_tz": -480
    },
    "id": "gnZL28MH2TMQ",
    "outputId": "c9b4b100-d1be-4d0d-f333-2b8e4299e367"
   },
   "outputs": [],
   "source": [
    "# Run the models on the Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZTjlVNQAaty"
   },
   "source": [
    "### Import the liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1x11QDZ4gM-"
   },
   "outputs": [],
   "source": [
    "# import pretrainedmodels\n",
    "# !pip install pretrainedmodels\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets ,transforms, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import helper\n",
    "import math\n",
    "import time as evaltime\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "#################################\n",
    "# If GPU is available, run the model in there \n",
    "device=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dS06clwVAngY"
   },
   "source": [
    "## Load the pre trained model and change the FC layer to taylor the number of classes: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "07ec6d1973ec4563af5e0f1d2ceed1b4",
      "bb0cb6ac86a1427781a4f607ba4431ab",
      "d4eda099769848e0a2ba1941ff339e96",
      "9203a9efa40b49a98468fa709e01ad33",
      "32221b5f1edf474abd82e0b6bd050f16",
      "fda18628ae1b4e0381a1087b4ccf9662",
      "941ffe5282d14275b014d4fb915bf29e",
      "ae0cc981122a4ba0be69e650b9eaef73"
     ]
    },
    "executionInfo": {
     "elapsed": 5761,
     "status": "ok",
     "timestamp": 1591273377685,
     "user": {
      "displayName": "FAEZEHSADAT SHAHIDI MAN181002",
      "photoUrl": "",
      "userId": "15928786153813768879"
     },
     "user_tz": -480
    },
    "id": "IOS1NXpCrYft",
    "outputId": "9f96b068-0162-492e-987f-70a07df847c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\" to /root/.cache/torch/checkpoints/resnext101_32x8d-8ba56ff5.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ec6d1973ec4563af5e0f1d2ceed1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=356082095.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained model \n",
    "ResNext101_2c= models.resnext101_32x8d(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CPqfxJOyr_Rd"
   },
   "outputs": [],
   "source": [
    "# Define the classifier\n",
    "classifier= nn.Sequential(OrderedDict([\n",
    "    ('0', nn.Linear(2048,1024)),\n",
    "    ('1',nn.ReLU(inplace=True)),\n",
    "    ('2', nn.Dropout(p=0.5)),\n",
    "    ('3', nn.Linear(1024,1024)),\n",
    "    ('4',nn.ReLU(inplace=True)),\n",
    "    ('5', nn.Dropout(p=0.5)),\n",
    "    ('6', nn.Linear(1024,8)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "    \n",
    "]))\n",
    "\n",
    "# Add the classifier to the model as the final layers \n",
    "ResNext101_2c.fc=classifier\n",
    "\n",
    "# Only the parameteres in the classifier needs to be retrained. \n",
    "for params in ResNext101_2c.parameters():\n",
    "    params.required_grad=False\n",
    "for params in ResNext101_2c.fc.parameters():\n",
    "    params.required_grad=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwfQ9qVHB2Rb"
   },
   "source": [
    "## Define the loss and optimization. in order to retrain the model, define the require grad true for all the parameters in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQhcL-6w3DQg"
   },
   "outputs": [],
   "source": [
    "critirion= nn.NLLLoss()\n",
    "optimizer = optim.Adam(ResNext101_2c.parameters(), lr=0.0002)\n",
    "ResNext101_2c.to(device)\n",
    "\n",
    "# Define the number of the classes and the model as the parameters, So they can be changed easily \n",
    "checkpoint=False\n",
    "classes=8\n",
    "model='resnext32'\n",
    "str_checkpoin=''\n",
    "check_dir=''\n",
    "start_epoch=1\n",
    "\n",
    "# Defne the model and classes that we defined as the parameters\n",
    "if checkpoint:\n",
    "  if classes==8:\n",
    "    str_checkpoin='To/checkpoints_8classes/'\n",
    "  else:\n",
    "    str_checkpoin='To/checkpoints/'\n",
    "\n",
    "  if model=='resnext32':\n",
    "    check_dir= str_checkpoin+'checkpoint_resnext101_32x8d_2c.pth'\n",
    "  elif model=='resnext64':\n",
    "    check_dir= str_checkpoin+'checkpoint_resnext101_64x4d_2c.pth'\n",
    "  elif model=='Inception_res_v2':\n",
    "    check_dir= str_checkpoin+'checkpoint_Inception_Res_V2_2c.pth'\n",
    "  elif model=='dpn':\n",
    "    check_dir= str_checkpoin+'checkpoint_dpn131_c2.pth'\n",
    "  elif model=='senet':\n",
    "    check_dir= str_checkpoin+'checkpoint_SeNet154_2c_finetune.pth'\n",
    "  elif model=='nasnet':\n",
    "    check_dir= str_checkpoin+'checkpoint_nasnetalarge_2c.pth'\n",
    "  stat_dict=torch.load(check_dir)\n",
    "  ResNext101_2c.load_state_dict(stat_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtNfhSBeCUlq"
   },
   "source": [
    "\n",
    "### Load the images to the train and test loader, with the ratio of 65/35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 117506,
     "status": "ok",
     "timestamp": 1591273553519,
     "user": {
      "displayName": "FAEZEHSADAT SHAHIDI MAN181002",
      "photoUrl": "",
      "userId": "15928786153813768879"
     },
     "user_tz": -480
    },
    "id": "a8BWg6-Y3Urt",
    "outputId": "9945eae0-ff7c-4a4a-e0d3-fb1a8cd45bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7919 ['adenosis', 'ductal_carcinoma', 'fibroadenoma', 'lobular_carcinoma', 'mucinous_carcinoma', 'papillary_carcinoma', 'phyllodes_tumor', 'tubular_adenoma']\n"
     ]
    }
   ],
   "source": [
    "dir_eight_Classes='To the brest cancer images for eight classifications/'\n",
    "dir_checkpoints='To the /checkpoints/'\n",
    "dir_statistics='To the/statistics/'\n",
    "\n",
    "# split the train and test datasets with the ration of 90/10\n",
    "ratio=0.9 \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    # transforms.RandomResizedCrop((224,224),scale=(0.08, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),(0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "\n",
    "# load the images to the train and test loader \n",
    "dataset= datasets.ImageFolder(dir_two_Classes,transform=train_transform)\n",
    "train_sample_len=math.ceil(len(dataset)*ratio)\n",
    "test_sample_len=len(dataset)-train_sample_len\n",
    "trainset,testset=torch.utils.data.random_split(dataset,[train_sample_len,test_sample_len] )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, num_workers=4, shuffle=True)\n",
    "testloader =torch.utils.data.DataLoader(testset, batch_size=1, num_workers=4, shuffle=False)\n",
    "classes=trainset.dataset.classes\n",
    "print( len(dataset), classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fwNVR8IChX_"
   },
   "source": [
    "### Displaying one image out of all to be confirmed that the trainset is already loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaOcXU_GCmQ3"
   },
   "outputs": [],
   "source": [
    "images=iter(testloader).next()\n",
    "type(images)\n",
    "images[0][0].shape\n",
    "img=images[0][0].permute(1,2,0)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rExcZPB4I-oy"
   },
   "source": [
    "### Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 28129479,
     "status": "ok",
     "timestamp": 1591301687606,
     "user": {
      "displayName": "FAEZEHSADAT SHAHIDI MAN181002",
      "photoUrl": "",
      "userId": "15928786153813768879"
     },
     "user_tz": -480
    },
    "id": "UVLZprO9Rbck",
    "outputId": "cd3ceb65-e5b1-4215-e450-21464d244ead"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "epochs = 94\n",
    "steps= 0\n",
    "print_every=100\n",
    "running_loss=0\n",
    "min_val_loss = np.Inf\n",
    "results={'epoch':[],'training_loss':[], 'test_loss':[], 'test_accuracy':[], 'training_accuracy':[]}\n",
    "\n",
    "# Iterate through the epoches\n",
    "for e in range(1,epochs+1):\n",
    "  running_results={'loss':0, 'accuracy':0,'minutes':0,'steps':0}\n",
    "  ResNext101_2c.train()\n",
    "  train_bar=tqdm(trainloader)\n",
    "  running_loss=0\n",
    "    \n",
    "   # Trian the model \n",
    "  for images, labels in train_bar:\n",
    "      start_time= evaltime.time()\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      running_results['steps']+=1\n",
    "      optimizer.zero_grad()\n",
    "      output=ResNext101_2c.forward(images)\n",
    "      ps=torch.exp(output)\n",
    "      loss=critirion(output,labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      # running_loss+=loss.item()\n",
    "      running_results['loss']+=loss.item()\n",
    "      equality = (ps.max(dim=1)[1]==labels.data)\n",
    "      running_results['accuracy']+=equality.type(torch.FloatTensor).mean()\n",
    "      train_bar.set_description(desc='[%d/%d], training_loss: %.4f, training_accuracy: %.4f '% \n",
    "                                (e,epochs, running_results['loss']/running_results['steps'],running_results['accuracy']/running_results['steps']))\n",
    "  test_bar=tqdm(testloader, desc='Validation Results:')\n",
    "  ResNext101_2c.eval()\n",
    "  valing_results={'test_loss':0, 'test_accuracy':0, 'min_loss':0, 'steps':0}\n",
    "\n",
    "  # Do not change the parameters while evaluating the model \n",
    "  with torch.no_grad():\n",
    "    # Test the model\n",
    "    for images, labels in test_bar: \n",
    "      valing_results['steps']+=1\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "      output=ResNext101_2c.forward(images)\n",
    "      loss=critirion(output,labels)\n",
    "      valing_results['test_loss']+= loss.item()\n",
    "      ps=torch.exp(output)\n",
    "      equality = (ps.max(dim=1)[1]==labels.data)\n",
    "      valing_results['test_accuracy']+=equality.type(torch.FloatTensor).mean()\n",
    "      test_bar.set_description(desc='test_loss: %.4f, test_accuracy: %.4f'%\n",
    "                               (valing_results['test_loss']/valing_results['steps'], valing_results['test_accuracy']/valing_results['steps'] ))\n",
    "    if (valing_results['test_loss']/valing_results['steps']< min_val_loss):\n",
    "            min_val_loss=valing_results['test_loss']/valing_results['steps']\n",
    "            print('saving the model with min loss of : '+ str(min_val_loss))\n",
    "            torch.save(ResNext101_2c.state_dict(),dir_checkpoints+\"dataaug_FT1024_checkpoint_resnext101_32x8d_2c.pth\")\n",
    "\n",
    "  # update the results for each epoch          \n",
    "  results['training_loss'].append(running_results['loss']/running_results['steps'])\n",
    "  results['test_loss'].append(valing_results['test_loss']/valing_results['steps'])\n",
    "  results['test_accuracy'].append(valing_results['test_accuracy'].item()/valing_results['steps'])\n",
    "  results['training_accuracy'].append(running_results['accuracy'].item()/running_results['steps'])\n",
    "  \n",
    "  data_frame=pd.DataFrame(\n",
    "        data={\n",
    "            # 'Epoch':1,\n",
    "            'Training_Loss':results['training_loss'],\n",
    "            'Test_Loss': results['test_loss'],\n",
    "            'Test_Accuracy':results['test_accuracy'],\n",
    "            'Training_Accuracy':results['training_accuracy'],\n",
    "           \n",
    "                 },\n",
    "        index=range(1,e+1)\n",
    "    )\n",
    "  # Save the results into a CSV file \n",
    "  data_frame.to_csv(dir_statistics+ 'dataaug_FT1024_Resnext101_32x8d_eval_results.csv',  index_label=\"Epoch\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e88zcuxCSBFT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1.1_FineTune_ResNext101(32x4d)_Breakhis_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07ec6d1973ec4563af5e0f1d2ceed1b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d4eda099769848e0a2ba1941ff339e96",
       "IPY_MODEL_9203a9efa40b49a98468fa709e01ad33"
      ],
      "layout": "IPY_MODEL_bb0cb6ac86a1427781a4f607ba4431ab"
     }
    },
    "32221b5f1edf474abd82e0b6bd050f16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9203a9efa40b49a98468fa709e01ad33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae0cc981122a4ba0be69e650b9eaef73",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_941ffe5282d14275b014d4fb915bf29e",
      "value": " 340M/340M [00:02&lt;00:00, 165MB/s]"
     }
    },
    "941ffe5282d14275b014d4fb915bf29e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae0cc981122a4ba0be69e650b9eaef73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb0cb6ac86a1427781a4f607ba4431ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4eda099769848e0a2ba1941ff339e96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fda18628ae1b4e0381a1087b4ccf9662",
      "max": 356082095,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32221b5f1edf474abd82e0b6bd050f16",
      "value": 356082095
     }
    },
    "fda18628ae1b4e0381a1087b4ccf9662": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
